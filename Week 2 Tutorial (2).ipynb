{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41e20b5",
   "metadata": {},
   "source": [
    "Run the code cell below to begin, and select the \"Hide/show all code\" button to toggle code cells on/off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ddae065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> body {font-family: \"Roboto Condensed Light\", \"Roboto Condensed\";} h2 {padding: 10px 12px; background-color: #E64626; position: static; color: #ffffff; font-size: 40px;} .text_cell_render p { font-size: 15px; } .text_cell_render h1 { font-size: 30px; } h1 {padding: 10px 12px; background-color: #E64626; color: #ffffff; font-size: 40px;} .text_cell_render h3 { padding: 10px 12px; background-color: #0148A4; position: static; color: #ffffff; font-size: 20px;} h4:before{ \n",
       "    content: \"@\"; font-family:\"Wingdings\"; font-style:regular; margin-right: 4px;} .text_cell_render h4 {padding: 8px; font-family: \"Roboto Condensed Light\"; position: static; font-style: italic; background-color: #FFB800; color: #ffffff; font-size: 18px; text-align: center; border-radius: 5px;}input[type=submit] {background-color: #E64626; border: solid; border-color: #734036; color: white; padding: 8px 16px; text-decoration: none; margin: 4px 2px; cursor: pointer; border-radius: 20px;}</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA2001 Week 2 Tutorial\n",
    "# Material last updated: 28 Feb 2023\n",
    "# Note: this notebook was designed with the Roboto Condensed font, which can be installed here: https://www.1001fonts.com/roboto-condensed-font.html\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "    <style> body {font-family: \"Roboto Condensed Light\", \"Roboto Condensed\";} h2 {padding: 10px 12px; background-color: #E64626; position: static; color: #ffffff; font-size: 40px;} .text_cell_render p { font-size: 15px; } .text_cell_render h1 { font-size: 30px; } h1 {padding: 10px 12px; background-color: #E64626; color: #ffffff; font-size: 40px;} .text_cell_render h3 { padding: 10px 12px; background-color: #0148A4; position: static; color: #ffffff; font-size: 20px;} h4:before{ \n",
    "    content: \"@\"; font-family:\"Wingdings\"; font-style:regular; margin-right: 4px;} .text_cell_render h4 {padding: 8px; font-family: \"Roboto Condensed Light\"; position: static; font-style: italic; background-color: #FFB800; color: #ffffff; font-size: 18px; text-align: center; border-radius: 5px;}input[type=submit] {background-color: #E64626; border: solid; border-color: #734036; color: white; padding: 8px 16px; text-decoration: none; margin: 4px 2px; cursor: pointer; border-radius: 20px;}</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9424826",
   "metadata": {},
   "source": [
    "# Week 2 - Data Exploration with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3032c7",
   "metadata": {},
   "source": [
    "Welcome to your first tutorial for DATA2x01! We are excited to guide you through a course that should prove both challenging and relevant in a world dominated by DATA. Each week will feature a set of coding exercises, of which your tutor will demonstrate some, while others will be left as an exercise for you to complete.\n",
    "\n",
    "The topic for this week is exploratory data analysis with Python, namely using `pandas` and `matplotlib` to perform initial data wrangling and visualisation on **Apple Music** Data from one of our 2022 tutors. Both offer detailed streaming history, but for simplicity, this tutorial focuses on the **music library** of songs itself.\n",
    "\n",
    "Note: if you happen to be an Apple Music customer yourself, feel free to download a [copy of your own data](https://privacy.apple.com), and use this instead of the dataset we provide. Alternatively, Spotify users may still be interested in their information, and this can be downloaded [here](https://www.spotify.com/us/account/privacy), though this wonâ€™t be as useful for this tutorial (less in-depth, in JSON not CSV form, and contains other fascinating/frightening details, such as defining users based on their listening preferences e.g. \"in-car listening\", \"fitness\" or \"studying or focussing\"). Both also take a couple days to prepare, so you may have to return at a later date to re-crunch the numbers on your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e656f2",
   "metadata": {},
   "source": [
    "## 1. Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca0d0a",
   "metadata": {},
   "source": [
    "First, we need to import the necessary modules to run this notebook. It is **good practice** to include these at the start of your notebook so someone else running your work can see the modules required to run this on their own device.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f96ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff22b4a",
   "metadata": {},
   "source": [
    "### 1.1 Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a473b",
   "metadata": {},
   "source": [
    "We need to import our data before we can do anything with it! Make sure you have downloaded `W2_AppleMusic.csv` from Canvas and store it in the same directory as this notebook, or adjust the filepath below if you plan on storing it elsewhere.\n",
    "\n",
    "A first step will often involve gauging how much data we have using `.shape`, and to take a glimpse of the first few rows using `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82baab83",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'W2_AppleMusic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yaraslauivashynka/Desktop/projects/DATA2901_Assign/Week 2 Tutorial (2).ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yaraslauivashynka/Desktop/projects/DATA2901_Assign/Week%202%20Tutorial%20%282%29.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m rawData \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mW2_AppleMusic.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yaraslauivashynka/Desktop/projects/DATA2901_Assign/Week%202%20Tutorial%20%282%29.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mShape of the data:\u001b[39m\u001b[39m\"\u001b[39m, rawData\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yaraslauivashynka/Desktop/projects/DATA2901_Assign/Week%202%20Tutorial%20%282%29.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m rawData\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     f,\n\u001b[1;32m   1219\u001b[0m     mode,\n\u001b[1;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1226\u001b[0m )\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'W2_AppleMusic.csv'"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv('W2_AppleMusic.csv')\n",
    "print(\"Shape of the data:\", rawData.shape)\n",
    "rawData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b84d9",
   "metadata": {},
   "source": [
    "### 1.2 Prepare a working copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e618b54",
   "metadata": {},
   "source": [
    "It is once again **good practice** to make sure your raw data is immutable in case of any accidental, irreversible changes. The `.copy()` function can create a working copy of the data.\n",
    "\n",
    "Additionally, since we are not interested in all of the 53 columns, we can take a subset using the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e43c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData = rawData.copy()\n",
    "wrkData = wrkData[['Title', 'Artist', 'Composer', 'Album', 'Genre', 'Track Year', 'Track Number On Album', 'Track Count On Album', 'Track Duration', 'Track Play Count', 'Date Added To Library', 'Last Played Date', 'Skip Count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844abd7",
   "metadata": {},
   "source": [
    "It is generally good practice to make sure your column names are of the same style. The `.rename()` function allows this to be achieved with ease.\n",
    "#### Can you think of other variable naming styles?  What are some of the challenges of having spaces in variable names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd79457",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData.rename(columns={\n",
    "    'Track Year': 'Year',\n",
    "    'Track Number On Album': 'TrackNo',\n",
    "    'Track Count On Album': 'AlbumTracks',\n",
    "    'Track Duration': 'DurationMs',\n",
    "    'Track Play Count': 'Plays',\n",
    "    'Date Added To Library': 'Added',\n",
    "    'Last Played Date': 'LastPlayed',\n",
    "    'Skip Count': 'Skips'\n",
    "}, inplace=True)\n",
    "wrkData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb409bf",
   "metadata": {},
   "source": [
    "### 1.3 Initial investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461eb742",
   "metadata": {},
   "source": [
    "Now that we have done some initial data wrangling, let's trial extracting smaller **subsets**, and investigate some data quality issues on the way. Notice how we can access all columns of the data and only some rows using the following code. It's also possible to extract just a few columns, by naming them in a list after the comma.\n",
    "\n",
    "From the subset extracted below, what are some of the data quality concerns here? How could we rectify them? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData.loc[[507, 870, 2736], ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a8fc99",
   "metadata": {},
   "source": [
    "A simple step that might prove worthwhile is to drop songs where the artist field is unpopulated. We could drop all rows with blanks in any field using the basic `.dropna()` function, but this may not be wisest. Songs which haven't been played but are still in the library for example, are probably worth keeping.\n",
    "\n",
    "We can tailor this process by only specifying the \"Artist\" field to drop nulls from, and confirm how the size of the dataset has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b012cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData.dropna(subset=['Artist'], inplace=True)\n",
    "wrkData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cfea0",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce169d4",
   "metadata": {},
   "source": [
    "Equipped with the knowledge of some key quality issues, it's important we actually try and fix some of them! This can involve a variety of different techniques depending on what data you have, and what the **goal** of your analysis is. This stage is where your duplicated data frame becomes very important, so that the raw data remains intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c18fc9",
   "metadata": {},
   "source": [
    "### 2.1 Removing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a2cb6",
   "metadata": {},
   "source": [
    "If we have a look at the `Year` column, we can see that there is entries that have been inputted as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3707d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(wrkData.Year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3915b5",
   "metadata": {},
   "source": [
    "#### Why is it problematic to leave `Year` as 0 for some rows even if we know it's a place holder?\n",
    "We can change all rows where this occurs to have their `Year` replaced by `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData.loc[wrkData['Year'] == 0, 'Year'] = None\n",
    "min(wrkData.Year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa558572",
   "metadata": {},
   "source": [
    "### 2.2 Date types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9031365",
   "metadata": {},
   "source": [
    "It is best to have a look at each column and see what `pandas` has interpreted the data type of each column to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0bfc4",
   "metadata": {},
   "source": [
    "While most of these seem okay, the `Added` and `LastPlayed` columns hold Date information, but are being interpreted as text. To facilitate any calculations on these columns, we should convert to the proper data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd13284",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData['Added'] = pd.to_datetime(wrkData['Added'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b2a82e",
   "metadata": {},
   "source": [
    "**Task: Convert the `LastPlayed` column to a date field**\n",
    "\n",
    "Note: you will get an error when you first attempt this! Investigate why this might be, correct it, and then proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d35d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527157c",
   "metadata": {},
   "source": [
    "## 3. Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22890bfb",
   "metadata": {},
   "source": [
    "### 3.1 Additional numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec884610",
   "metadata": {},
   "source": [
    "`DurationMs` is recorded in milliseconds, which is a level of detail beyond what's useful for our reporting. Columns can be redefined in place, such as below, where this has been converted to the nearest second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43967be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData['Duration'] = round(wrkData['DurationMs'] / 1000)\n",
    "wrkData.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece1e1bf",
   "metadata": {},
   "source": [
    "String operations can be undertaken as well. For example, some genres involve a split (e.g. \"Hip Hop/Rap\"). We may wish to naively enumerate how many extra genres are listed, and could do so with the below code (note the 4th row - index 3 - yields 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData['ExtraGenres'] = wrkData['Genre'].str.count('/')\n",
    "wrkData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39537c0c",
   "metadata": {},
   "source": [
    "Another column of interest could be `Composer`. Notice how for some songs there is only 1, while for others there is a few. \n",
    "#### How would we best count the number of composers for each song?\n",
    "Additionally, what sort of assumptions would we be making here? These questions are important to both consider in your data pipeline, as well as to note down and document in deliverables.\n",
    "<br><br>\n",
    "**Task: Create a new column `ComposerCount` which counts the number of composers each song has**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19d2f6",
   "metadata": {},
   "source": [
    "### 3.2 Additional categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a00deb",
   "metadata": {},
   "source": [
    "We may also want to provide categorical columns which act as 'flags' for the presence of a particular value. Conditional columns can be defined using the `np.where()` function. The simple example below defines all Harry Styles songs as currently \"on tour\", given he is currently in Australia, then returns only songs with \"Sign\" in the title to confirm its success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData['OnTour'] = np.where(wrkData['Artist'] == 'Harry Styles', 'Y', 'N')\n",
    "wrkData.loc[wrkData['Title'].str.contains('Sign'), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364206a",
   "metadata": {},
   "source": [
    "For a more practical example, let's say we are interested in creating a flag to warn of songs that contain potentially explicit language.\n",
    "\n",
    "We can first have a look at what `Genre`'s we have and consider which may be susceptible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27593259",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData.Genre.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965c8b5",
   "metadata": {},
   "source": [
    "**Task: Create a new column `SFW` (\"safe for work\") which flags whether a song is potentially explicit**\n",
    "\n",
    "For simplicity, define all songs with 'Rap' in the genre as unsafe to play when parents or young children are around. Feel free to extend this if desired!\n",
    "\n",
    "Confirm your success by printing all songs with the \"Black Eyed Peas\" as the artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c41bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c206ff",
   "metadata": {},
   "source": [
    "## 4. Analysing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b43725",
   "metadata": {},
   "source": [
    "Now that we have wrangled the data, let's actually analyse it! The form of the analysis will come down to the desired output as well as scope, but for this exercise we will do some exploratory data analysis and show some of the interesting features of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433790a",
   "metadata": {},
   "source": [
    "### 4.1 Ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2018653",
   "metadata": {},
   "source": [
    "When thinking about our music data, some interesting questions may come to mind: \n",
    "- What was the last song played by the user? \n",
    "- What was the first song added to their library? \n",
    "- According to their most played songs, what is their favourite artist?\n",
    "\n",
    "Notice how once data cleaning, though arduous, is completed, these sorts of questions can be answered with ease and little code.\n",
    "\n",
    "**Task: Write code to answer the above questions.**\n",
    "\n",
    "Use the [`.sort_values()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) or [`.nlargest()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html) functions to answer the questions, and investigate the Pandas documentation (linked) to understand more about how these operations can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b6c462",
   "metadata": {},
   "source": [
    "### 4.2 Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2999a9a",
   "metadata": {},
   "source": [
    "Another technique is using one variable to aggregate over other aspects of the data. For example, we may be interested in the most prevalent artists in the dataset.\n",
    "\n",
    "We can create a new dataframe with one row per artist rather than per song, by **\"grouping by\"** artist. This concept will return in later weeks of SQL, and might take a bit to get used to at first!\n",
    "\n",
    "From there, we can instruct it to count how many titles exist for each, using the `.agg()` function, and assign that column as \"Songs\". From there we find the top 5, similarly to the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = wrkData.groupby('Artist').agg(Songs = ('Title','count')).reset_index()\n",
    "artists.sort_values(by=['Songs'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b7e645",
   "metadata": {},
   "source": [
    "**Task: Determine which genres have the greatest number of plays, and also include how many skips each genre has.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072762ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07226ae0",
   "metadata": {},
   "source": [
    "## 5. Visualising data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a75a9",
   "metadata": {},
   "source": [
    "The next natural step is to visualise the data. This could be a precursor to greater statistical investigation, or stand on its own for analysis. Revising the lectures notes and/or your first year statistics will prove helpful when determining the appropriate visualisations for specific data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6ee06",
   "metadata": {},
   "source": [
    "### 5.1 Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9ee47",
   "metadata": {},
   "source": [
    "Creating a histogram for songs by duration is a useful and satisfying representation of the data.\n",
    "\n",
    "The `bins` have been set at a minimum of 0 and maximum of 1200 seconds, which excludes a few outliers (there are a couple quite long songs in the dataset). The width of each bin range has also been set to 10 seconds, which can be adjusted for more abstract or refined visuals (try changing it!).\n",
    "\n",
    "Other aspects of the code below are purely aesthetic, such as plot titles, axis labels, colours, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(wrkData['Duration'], bins=np.arange(0,1200,10), alpha=0.5, color =\"#0148A4\")\n",
    "plt.title('Duration by Song')\n",
    "plt.xlabel('Duration (seconds)')\n",
    "plt.ylabel('Number of songs')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49bdd3",
   "metadata": {},
   "source": [
    "Alternatively, boxplots can be used to represent the same information in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(wrkData.loc[wrkData['Duration'] <= 1200, 'Duration'], vert=False)\n",
    "plt.title('Distribution of Duration')\n",
    "plt.xlabel('Duration (seconds)')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0b107",
   "metadata": {},
   "source": [
    "### 5.2 Bar charts with grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd53dce",
   "metadata": {},
   "source": [
    "We can also return to our `.groupby()` operation for graphs. The below is quite similar, but involves a bar chart for number of songs each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = wrkData.groupby('Year').size().reset_index(name='Songs')\n",
    "plt.bar(years['Year'], years['Songs'], alpha=0.5, color =\"#0148A4\", align='center')\n",
    "plt.title('Number of Songs Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of songs')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cecfbd9",
   "metadata": {},
   "source": [
    "### 5.3 Free choice visual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de0689",
   "metadata": {},
   "source": [
    "Now that you've seen how to visualise in Python, it's time to do your own!\n",
    "\n",
    "**Task: Consider a particular variable(s) of choice and make an interesting visualisation to explore.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3340f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d945e",
   "metadata": {},
   "source": [
    "## 6. Optional Extra Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb3463b",
   "metadata": {},
   "source": [
    "As an optional extension task - a practical use of this data could involve determining which genres the listener are most or least engaged with.\n",
    "\n",
    "**Optional Task: Determine which genres have the highest/lowest skip ratio**\n",
    "\n",
    "Only include genres with at least 10 encounters in your output, and the skip ratio = total skips divided by total encounters (the sum of plays and skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
